{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:59:44.699745535Z",
     "start_time": "2024-01-11T22:59:39.953272690Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patchify import patchify\n",
    "import tensorflow as tf\n",
    "from ViT import ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f383fbccdaa383"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hp = {}\n",
    "hp[\"image_size\"] = 200\n",
    "hp[\"num_channels\"] = 3\n",
    "hp[\"patch_size\"] = 25\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
    "\n",
    "hp[\"batch_size\"] = 32\n",
    "hp[\"lr\"] = 1e-4\n",
    "hp[\"num_epochs\"] = 500\n",
    "hp[\"num_classes\"] = 5\n",
    "hp[\"class_names\"] = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
    "\n",
    "hp[\"num_layers\"] = 12\n",
    "hp[\"hidden_dim\"] = 768\n",
    "hp[\"mlp_dim\"] = 3072\n",
    "hp[\"num_heads\"] = 12\n",
    "hp[\"dropout_rate\"] = 0.1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:59:46.374516077Z",
     "start_time": "2024-01-11T22:59:46.350738082Z"
    }
   },
   "id": "c11a1d058f65f8e2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)\n",
    "\t\t\n",
    "\t\t\n",
    "def load_data(path, split=0.1):\n",
    "\timages = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
    "\t# print(images)\n",
    "\tsplit_size = int(len(images) * split)\n",
    "\t# print(split_size)\n",
    "\ttrain_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "\ttrain_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "\t\n",
    "\treturn train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "\t\"\"\"Reading images\"\"\"\n",
    "\tpath = path.decode()\n",
    "\timage = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\timage = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "\timage = image/255.0\n",
    "\t# print(image.shape)\n",
    "\t\n",
    "\t\"\"\" Preprocessing to patches \"\"\"\n",
    "\tpatch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "\tpatches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "\t# print(patches.shape)\n",
    "\t\n",
    "\t# patches = np.reshape(patches, (64, 25, 25, 3))\n",
    "\t# for i in range(64):\n",
    "\t# \tcv2.imwrite(f\"./files/{i}.png\", patches[i])\n",
    "\t\n",
    "\tpatches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "\tpatches = patches.astype(np.float32)\n",
    "\t\n",
    "\t\n",
    "\t\"\"\" Label \"\"\"\n",
    "\tclass_name = path.split(\"/\")[-2]\n",
    "\tclass_index = hp[\"class_names\"].index(class_name)\n",
    "\tclass_index = np.array(class_index, dtype=np.int32)\n",
    "\t\n",
    "\treturn patches, class_index\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "\tpatches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "\tlabels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\t\n",
    "\tpatches.set_shape(hp[\"flat_patches_shape\"])\n",
    "\tlabels.set_shape(hp[\"num_classes\"])\n",
    "\t\n",
    "\treturn patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "\tds = tf.data.Dataset.from_tensor_slices((images))\n",
    "\tds = ds.map(parse).batch(batch).prefetch(8)\n",
    "\treturn ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:59:47.518535301Z",
     "start_time": "2024-01-11T22:59:47.458146449Z"
    }
   },
   "id": "57e5202b73773c4e",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seeding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a10db77b38d0a4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:59:49.380975664Z",
     "start_time": "2024-01-11T22:59:49.360327787Z"
    }
   },
   "id": "1f08a8402837501f",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### \"i\" Directory for storing files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c1befafaf84abb4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "create_dir(\"files\")\n",
    "\n",
    "# Path to Dataset\n",
    "dataset_path = os.path.join(\"flower_photos\")\n",
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "csv_path = os.path.join(\"files\", \"log.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:59:50.885126279Z",
     "start_time": "2024-01-11T22:59:50.865252902Z"
    }
   },
   "id": "2f4493712201c5df",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2936 - Valid: 367 - Test: 367\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, test_x = load_data(dataset_path)\n",
    "print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T22:59:52.028933509Z",
     "start_time": "2024-01-11T22:59:51.979408460Z"
    }
   },
   "id": "4135fc9332a6f3d1",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_ds = tf_dataset(train_x, batch=hp[\"batch_size\"])\n",
    "valid_ds = tf_dataset(valid_x, batch=hp[\"batch_size\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T23:41:35.506544437Z",
     "start_time": "2024-01-11T23:41:35.462677487Z"
    }
   },
   "id": "8067bd1f06ae9297",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff04d81de2cf244a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "\n",
    "model = ViT(hp)\n",
    "model.compile(\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\toptimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "\tmetrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "\tModelCheckpoint(model_path, monitor=\"val_loss\", verbose=1, save_best_only=True),\n",
    "\tReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=10, min_lr=1e-1, verbose=1),\n",
    "\tCSVLogger(csv_path),\n",
    "\tEarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=False)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f751115ec73bca61",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.fit(\n",
    "\ttrain_ds,\n",
    "    epochs=hp[\"num_epochs\"],\n",
    "\tvalidation_data=valid_ds,\n",
    "\tcallbacks=callbacks\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b31c24c38c0e46c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
